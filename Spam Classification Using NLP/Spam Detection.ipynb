{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76339230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ZARRAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f3a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\")\n",
    "df = pd.DataFrame(csv)#series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feccad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f653d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 108.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910db238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "classes = df[df.columns[0]]\n",
    "classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eaabb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rno v1 Encoded\n",
      "0 ham \t 0\n",
      "1 ham \t 0\n",
      "2 spam \t 1\n",
      "3 ham \t 0\n",
      "4 ham \t 0\n",
      "5 spam \t 1\n",
      "6 ham \t 0\n",
      "7 ham \t 0\n",
      "8 spam \t 1\n",
      "9 spam \t 1\n"
     ]
    }
   ],
   "source": [
    "# convert class labels to binary values, 0 = ham  1 = spam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "\n",
    "# quick check\n",
    "print('rno v1 Encoded')\n",
    "for i in range(0,10):\n",
    "    print(i,classes[i],'\\t', Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3daafb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: v2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# store SMS message data\n",
    "text_messages = df[df.columns[1]]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b5efed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ea7df8d1124e>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddr')\n",
      "<ipython-input-32-ea7df8d1124e>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
      "<ipython-input-32-ea7df8d1124e>:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'£|\\$', 'moneysymb')\n",
      "<ipython-input-32-ea7df8d1124e>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'^[2-9]\\d{2}-\\d{3}-\\d{4}$', 'phonenum')\n",
      "<ipython-input-32-ea7df8d1124e>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'\\d+(\\.\\d+)?', 'num')\n"
     ]
    }
   ],
   "source": [
    "# expressions can be found at https://regexlib.com/\n",
    "# use regular expressions to replace email addresses, urls, phone numbers, etc.\n",
    "\n",
    "# replace email addresses with 'emailaddr\n",
    "processed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddr')\n",
    "# replace urls with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "# replace money symbols with 'moneysymb'\n",
    "processed = text_messages.str.replace(r'£|\\$', 'moneysymb')\n",
    "# replace 10 digit phone numbers with 'phonenum'\n",
    "processed = text_messages.str.replace(r'^[2-9]\\d{2}-\\d{3}-\\d{4}$', 'phonenum')\n",
    "\n",
    "# replace normal numbers with 'num'\n",
    "processed = text_messages.str.replace(r'\\d+(\\.\\d+)?', 'num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "715fb664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-0afdbb470505>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "<ipython-input-33-0afdbb470505>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\s+', ' ')\n",
      "<ipython-input-33-0afdbb470505>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecc112a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazy available only in ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry in num a wkly comp to win fa cup fi...\n",
       "3          u dun say so early hor u c already then say\n",
       "4    nah i don t think he goes to usf he lives arou...\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change all words to lower case\n",
    "processed = processed.str.lower()\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43ee84c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazy available bugis n great ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry num wkly comp win fa cup final tkts...\n",
       "3                  u dun say early hor u c already say\n",
       "4               nah think goes usf lives around though\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stop words from text messages\n",
    "# stop words are basically a set of commonly used words in any language such as i, me, to, it, etc.\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: \n",
    "        ' '.join(term for term in x.split() if term not in stop_words)\n",
    "        )\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a88cc4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazi avail bugi n great world...\n",
       "1                                ok lar joke wif u oni\n",
       "2    free entri num wkli comp win fa cup final tkt ...\n",
       "3                  u dun say earli hor u c alreadi say\n",
       "4                 nah think goe usf live around though\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove word stems using a Porter stemmer\n",
    "# stemming is the process of reducing a word to its word stem such as removing -ing\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: \n",
    "    ' '.join(ps.stem(term) for term in x.split()))\n",
    "\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcacac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ZARRAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# create bag-of-words\n",
    "all_words = []\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "\n",
    "# FreqDist class is used to encode “frequency distributions”, which count the number of times that each outcome of an experiment occurs\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be3e83ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'num': 2959, 'u': 1192, 'call': 672, 'go': 453, 'get': 452, 'ur': 385, 'gt': 318, 'lt': 316, 'å': 303, 'come': 301, ...})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d506874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 6534\n",
      "Most common words: [('num', 2959), ('u', 1192), ('call', 672), ('go', 453), ('get', 452), ('ur', 385), ('gt', 318), ('lt', 316), ('å', 303), ('come', 301)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and the 15 most common words\n",
    "print(f'Number of words: {format(len(all_words))}')\n",
    "print(f'Most common words: {format(all_words.most_common(10))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32e04110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazi',\n",
       " 'avail',\n",
       " 'bugi',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amor',\n",
       " 'wat',\n",
       " 'ok',\n",
       " 'lar',\n",
       " 'joke',\n",
       " 'wif',\n",
       " 'u',\n",
       " 'oni',\n",
       " 'free',\n",
       " 'entri',\n",
       " 'num',\n",
       " 'wkli',\n",
       " 'comp',\n",
       " 'win',\n",
       " 'fa',\n",
       " 'cup',\n",
       " 'final',\n",
       " 'tkt',\n",
       " 'numst',\n",
       " 'may',\n",
       " 'text',\n",
       " 'receiv',\n",
       " 'question',\n",
       " 'std',\n",
       " 'txt',\n",
       " 'rate',\n",
       " 'c',\n",
       " 'appli',\n",
       " 'numovernum',\n",
       " 'dun',\n",
       " 'say',\n",
       " 'earli',\n",
       " 'hor',\n",
       " 'alreadi',\n",
       " 'nah',\n",
       " 'think',\n",
       " 'goe',\n",
       " 'usf',\n",
       " 'live',\n",
       " 'around',\n",
       " 'though',\n",
       " 'freemsg',\n",
       " 'hey',\n",
       " 'darl',\n",
       " 'week',\n",
       " 'word',\n",
       " 'back',\n",
       " 'like',\n",
       " 'fun',\n",
       " 'still',\n",
       " 'tb',\n",
       " 'xxx',\n",
       " 'chg',\n",
       " 'send',\n",
       " 'å',\n",
       " 'rcv',\n",
       " 'even',\n",
       " 'brother',\n",
       " 'speak',\n",
       " 'treat',\n",
       " 'aid',\n",
       " 'patent',\n",
       " 'per',\n",
       " 'request',\n",
       " 'mell',\n",
       " 'oru',\n",
       " 'minnaminungint',\n",
       " 'nurungu',\n",
       " 'vettam',\n",
       " 'set',\n",
       " 'callertun',\n",
       " 'caller',\n",
       " 'press',\n",
       " 'copi',\n",
       " 'friend',\n",
       " 'winner',\n",
       " 'valu',\n",
       " 'network',\n",
       " 'custom',\n",
       " 'select',\n",
       " 'receivea',\n",
       " 'prize',\n",
       " 'reward',\n",
       " 'claim',\n",
       " 'call',\n",
       " 'code',\n",
       " 'klnum',\n",
       " 'valid',\n",
       " 'hour',\n",
       " 'mobil',\n",
       " 'month',\n",
       " 'r',\n",
       " 'entitl',\n",
       " 'updat',\n",
       " 'latest',\n",
       " 'colour',\n",
       " 'camera',\n",
       " 'co',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'home',\n",
       " 'soon',\n",
       " 'want',\n",
       " 'talk',\n",
       " 'stuff',\n",
       " 'anymor',\n",
       " 'tonight',\n",
       " 'k',\n",
       " 'cri',\n",
       " 'enough',\n",
       " 'today',\n",
       " 'six',\n",
       " 'chanc',\n",
       " 'cash',\n",
       " 'pound',\n",
       " 'cshnum',\n",
       " 'cost',\n",
       " 'nump',\n",
       " 'day',\n",
       " 'numday',\n",
       " 'tsandc',\n",
       " 'repli',\n",
       " 'hl',\n",
       " 'info',\n",
       " 'urgent',\n",
       " 'membership',\n",
       " 'jackpot',\n",
       " 'www',\n",
       " 'dbuk',\n",
       " 'net',\n",
       " 'lccltd',\n",
       " 'pobox',\n",
       " 'numldnwnumanumrwnum',\n",
       " 'search',\n",
       " 'right',\n",
       " 'thank',\n",
       " 'breather',\n",
       " 'promis',\n",
       " 'wont',\n",
       " 'take',\n",
       " 'help',\n",
       " 'grant',\n",
       " 'fulfil',\n",
       " 'wonder',\n",
       " 'bless',\n",
       " 'time',\n",
       " 'date',\n",
       " 'sunday',\n",
       " 'xxxmobilemovieclub',\n",
       " 'use',\n",
       " 'credit',\n",
       " 'click',\n",
       " 'wap',\n",
       " 'link',\n",
       " 'next',\n",
       " 'messag',\n",
       " 'http',\n",
       " 'com',\n",
       " 'qjkgighjjgcbl',\n",
       " 'oh',\n",
       " 'watch',\n",
       " 'eh',\n",
       " 'rememb',\n",
       " 'spell',\n",
       " 'name',\n",
       " 'ye',\n",
       " 'v',\n",
       " 'naughti',\n",
       " 'make',\n",
       " 'wet',\n",
       " 'fine',\n",
       " 'thatåõ',\n",
       " 'way',\n",
       " 'feel',\n",
       " 'gota',\n",
       " 'b',\n",
       " 'england',\n",
       " 'macedonia',\n",
       " 'dont',\n",
       " 'miss',\n",
       " 'goal',\n",
       " 'team',\n",
       " 'news',\n",
       " 'ur',\n",
       " 'nation',\n",
       " 'eg',\n",
       " 'tri',\n",
       " 'wale',\n",
       " 'scotland',\n",
       " 'numtxt',\n",
       " 'ì¼num',\n",
       " 'poboxoxnumwnumwq',\n",
       " 'serious',\n",
       " 'û',\n",
       " 'ha',\n",
       " 'ì_',\n",
       " 'pay',\n",
       " 'first',\n",
       " 'da',\n",
       " 'stock',\n",
       " 'comin',\n",
       " 'aft',\n",
       " 'finish',\n",
       " 'lunch',\n",
       " 'str',\n",
       " 'lor',\n",
       " 'ard',\n",
       " 'smth',\n",
       " 'ffffffffff',\n",
       " 'alright',\n",
       " 'meet',\n",
       " 'sooner',\n",
       " 'forc',\n",
       " 'eat',\n",
       " 'slice',\n",
       " 'realli',\n",
       " 'hungri',\n",
       " 'tho',\n",
       " 'suck',\n",
       " 'mark',\n",
       " 'get',\n",
       " 'worri',\n",
       " 'know',\n",
       " 'sick',\n",
       " 'turn',\n",
       " 'pizza',\n",
       " 'lol',\n",
       " 'alway',\n",
       " 'convinc',\n",
       " 'catch',\n",
       " 'bu',\n",
       " 'fri',\n",
       " 'egg',\n",
       " 'tea',\n",
       " 'mom',\n",
       " 'left',\n",
       " 'dinner',\n",
       " 'love',\n",
       " 'amp',\n",
       " 'pack',\n",
       " 'car',\n",
       " 'let',\n",
       " 'room',\n",
       " 'ahhh',\n",
       " 'work',\n",
       " 'vagu',\n",
       " 'wait',\n",
       " 'clear',\n",
       " 'sure',\n",
       " 'sarcast',\n",
       " 'x',\n",
       " 'us',\n",
       " 'yeah',\n",
       " 'apologet',\n",
       " 'fallen',\n",
       " 'actin',\n",
       " 'spoilt',\n",
       " 'child',\n",
       " 'caught',\n",
       " 'till',\n",
       " 'badli',\n",
       " 'cheer',\n",
       " 'tell',\n",
       " 'anyth',\n",
       " 'fear',\n",
       " 'faint',\n",
       " 'housework',\n",
       " 'quick',\n",
       " 'cuppa',\n",
       " 'subscript',\n",
       " 'rington',\n",
       " 'uk',\n",
       " 'charg',\n",
       " 'pleas',\n",
       " 'confirm',\n",
       " 'yup',\n",
       " 'look',\n",
       " 'msg',\n",
       " 'xuhui',\n",
       " 'learn',\n",
       " 'numnd',\n",
       " 'lesson',\n",
       " 'numam',\n",
       " 'oop',\n",
       " 'roommat',\n",
       " 'done',\n",
       " 'see',\n",
       " 'letter',\n",
       " 'decid',\n",
       " 'hello',\n",
       " 'saturday',\n",
       " 'tomo',\n",
       " 'invit',\n",
       " 'pl',\n",
       " 'ahead',\n",
       " 'watt',\n",
       " 'weekend',\n",
       " 'abiola',\n",
       " 'forget',\n",
       " 'need',\n",
       " 'crave',\n",
       " 'sweet',\n",
       " 'arabian',\n",
       " 'steed',\n",
       " 'mmmmmm',\n",
       " 'yummi',\n",
       " 'rodger',\n",
       " 'burn',\n",
       " 'sm',\n",
       " 'nokia',\n",
       " 'camcord',\n",
       " 'deliveri',\n",
       " 'tomorrow',\n",
       " 'hope',\n",
       " 'man',\n",
       " 'well',\n",
       " 'endow',\n",
       " 'lt',\n",
       " 'gt',\n",
       " 'inch',\n",
       " 'hep',\n",
       " 'immunis',\n",
       " 'nigeria',\n",
       " 'fair',\n",
       " 'tyler',\n",
       " 'could',\n",
       " 'mayb',\n",
       " 'ask',\n",
       " 'bit',\n",
       " 'stubborn',\n",
       " 'hospit',\n",
       " 'kept',\n",
       " 'weak',\n",
       " 'sucker',\n",
       " 'saw',\n",
       " 'class',\n",
       " 'gram',\n",
       " 'usual',\n",
       " 'run',\n",
       " 'half',\n",
       " 'eighth',\n",
       " 'smarter',\n",
       " 'almost',\n",
       " 'whole',\n",
       " 'second',\n",
       " 'fyi',\n",
       " 'ride',\n",
       " 'morn',\n",
       " 'crash',\n",
       " 'place',\n",
       " 'wow',\n",
       " 'never',\n",
       " 'realiz',\n",
       " 'embarass',\n",
       " 'accomod',\n",
       " 'thought',\n",
       " 'sinc',\n",
       " 'best',\n",
       " 'seem',\n",
       " 'happi',\n",
       " 'cave',\n",
       " 'sorri',\n",
       " 'give',\n",
       " 'offer',\n",
       " 'ac',\n",
       " 'sptv',\n",
       " 'new',\n",
       " 'jersey',\n",
       " 'devil',\n",
       " 'detroit',\n",
       " 'red',\n",
       " 'wing',\n",
       " 'play',\n",
       " 'ice',\n",
       " 'hockey',\n",
       " 'correct',\n",
       " 'incorrect',\n",
       " 'end',\n",
       " 'mallika',\n",
       " 'sherawat',\n",
       " 'yesterday',\n",
       " 'find',\n",
       " 'url',\n",
       " 'congrat',\n",
       " 'year',\n",
       " 'special',\n",
       " 'cinema',\n",
       " 'pass',\n",
       " 'suprman',\n",
       " 'matrixnum',\n",
       " 'starwarsnum',\n",
       " 'etc',\n",
       " 'bxnum',\n",
       " 'ipnum',\n",
       " 'numw',\n",
       " 'numpm',\n",
       " 'later',\n",
       " 'reach',\n",
       " 'gauti',\n",
       " 'sehwag',\n",
       " 'odi',\n",
       " 'seri',\n",
       " 'pick',\n",
       " 'burger',\n",
       " 'move',\n",
       " 'pain',\n",
       " 'kill',\n",
       " 'good',\n",
       " 'girl',\n",
       " 'situat',\n",
       " 'seeker',\n",
       " 'part',\n",
       " 'check',\n",
       " 'iq',\n",
       " 'took',\n",
       " 'forev',\n",
       " 'come',\n",
       " 'doubl',\n",
       " 'hair',\n",
       " 'dresser',\n",
       " 'said',\n",
       " 'wun',\n",
       " 'cut',\n",
       " 'short',\n",
       " 'nice',\n",
       " 'advis',\n",
       " 'follow',\n",
       " 'recent',\n",
       " 'review',\n",
       " 'mob',\n",
       " 'award',\n",
       " 'bonu',\n",
       " 'song',\n",
       " 'dedic',\n",
       " 'valuabl',\n",
       " 'frnd',\n",
       " 'rpli',\n",
       " 'complimentari',\n",
       " 'trip',\n",
       " 'eurodisinc',\n",
       " 'trav',\n",
       " 'aco',\n",
       " 'entrynum',\n",
       " 'di',\n",
       " 'morefrmmob',\n",
       " 'shracomorsglsuplt',\n",
       " 'lsnum',\n",
       " 'numaj',\n",
       " 'hear',\n",
       " 'divorc',\n",
       " 'barbi',\n",
       " 'ken',\n",
       " 'plane',\n",
       " 'wah',\n",
       " 'lucki',\n",
       " 'save',\n",
       " 'money',\n",
       " 'hee',\n",
       " 'hi',\n",
       " 'babe',\n",
       " 'im',\n",
       " 'wan',\n",
       " 'someth',\n",
       " 'xx',\n",
       " 'perform',\n",
       " 'machan',\n",
       " 'that',\n",
       " 'cool',\n",
       " 'gentleman',\n",
       " 'digniti',\n",
       " 'respect',\n",
       " 'peopl',\n",
       " 'much',\n",
       " 'shi',\n",
       " 'pa',\n",
       " 'oper',\n",
       " 'job',\n",
       " 'ta',\n",
       " 'earn',\n",
       " 'ah',\n",
       " 'stop',\n",
       " 'urgnt',\n",
       " 'real',\n",
       " 'yo',\n",
       " 'ticket',\n",
       " 'one',\n",
       " 'jacket',\n",
       " 'multi',\n",
       " 'start',\n",
       " 'came',\n",
       " 'bed',\n",
       " 'coin',\n",
       " 'factori',\n",
       " 'nitro',\n",
       " 'ela',\n",
       " 'kano',\n",
       " 'il',\n",
       " 'download',\n",
       " 'wen',\n",
       " 'stand',\n",
       " 'close',\n",
       " 'anoth',\n",
       " 'night',\n",
       " 'spent',\n",
       " 'late',\n",
       " 'afternoon',\n",
       " 'casualti',\n",
       " 'mean',\n",
       " 'stuffnummoro',\n",
       " 'includ',\n",
       " 'sheet',\n",
       " 'smile',\n",
       " 'pleasur',\n",
       " 'troubl',\n",
       " 'pour',\n",
       " 'rain',\n",
       " 'sumnum',\n",
       " 'hurt',\n",
       " 'becoz',\n",
       " 'someon',\n",
       " 'servic',\n",
       " 'repres',\n",
       " 'guarante',\n",
       " 'havent',\n",
       " 'plan',\n",
       " 'buy',\n",
       " 'lido',\n",
       " 'show',\n",
       " 'collect',\n",
       " 'simpli',\n",
       " 'password',\n",
       " 'mix',\n",
       " 'verifi',\n",
       " 'usher',\n",
       " 'britney',\n",
       " 'fml',\n",
       " 'telugu',\n",
       " 'movi',\n",
       " 'abt',\n",
       " 'load',\n",
       " 'loan',\n",
       " 'wk',\n",
       " 'hol',\n",
       " 'forgot',\n",
       " 'hairdress',\n",
       " 'appoint',\n",
       " 'four',\n",
       " 'shower',\n",
       " 'beforehand',\n",
       " 'caus',\n",
       " 'prob',\n",
       " 'ham',\n",
       " 'noth',\n",
       " 'els',\n",
       " 'okay',\n",
       " 'price',\n",
       " 'long',\n",
       " 'legal',\n",
       " 'ave',\n",
       " 'am',\n",
       " 'gone',\n",
       " 'numth',\n",
       " 'drive',\n",
       " 'test',\n",
       " 'yet',\n",
       " 'guess',\n",
       " 'gave',\n",
       " 'boston',\n",
       " 'men',\n",
       " 'chang',\n",
       " 'locat',\n",
       " 'nyc',\n",
       " 'cuz',\n",
       " 'signin',\n",
       " 'page',\n",
       " 'umma',\n",
       " 'life',\n",
       " 'vava',\n",
       " 'lot',\n",
       " 'dear',\n",
       " 'wish',\n",
       " 'birthday',\n",
       " 'truli',\n",
       " 'memor',\n",
       " 'aight',\n",
       " 'hit',\n",
       " 'would',\n",
       " 'ip',\n",
       " 'address',\n",
       " 'consid',\n",
       " 'comput',\n",
       " 'minecraft',\n",
       " 'server',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'better',\n",
       " 'lie',\n",
       " 'busi',\n",
       " 'plural',\n",
       " 'noun',\n",
       " 'research',\n",
       " 'thing',\n",
       " 'scare',\n",
       " 'mah',\n",
       " 'loud',\n",
       " 'gent',\n",
       " 'contact',\n",
       " 'last',\n",
       " 'draw',\n",
       " 'knum',\n",
       " 'numhr',\n",
       " 'numppm',\n",
       " 'wa',\n",
       " 'openin',\n",
       " 'sentenc',\n",
       " 'formal',\n",
       " 'anyway',\n",
       " 'juz',\n",
       " 'tt',\n",
       " 'eatin',\n",
       " 'puttin',\n",
       " 'weight',\n",
       " 'haha',\n",
       " 'anythin',\n",
       " 'happen',\n",
       " 'enter',\n",
       " 'cabin',\n",
       " 'boss',\n",
       " 'felt',\n",
       " 'askd',\n",
       " 'apart',\n",
       " 'went',\n",
       " 'holiday',\n",
       " 'flight',\n",
       " 'inc',\n",
       " 'min',\n",
       " 'goodo',\n",
       " 'must',\n",
       " 'friday',\n",
       " 'potato',\n",
       " 'ratio',\n",
       " 'tortilla',\n",
       " 'hmm',\n",
       " 'uncl',\n",
       " 'inform',\n",
       " 'school',\n",
       " 'directli',\n",
       " 'food',\n",
       " 'privat',\n",
       " 'account',\n",
       " 'statement',\n",
       " 'unredeem',\n",
       " 'identifi',\n",
       " 'expir',\n",
       " 'landlin',\n",
       " 'boxnumwrnumc',\n",
       " 'appl',\n",
       " 'pair',\n",
       " 'malarki',\n",
       " 'voda',\n",
       " 'number',\n",
       " 'match',\n",
       " 'quot',\n",
       " 'standard',\n",
       " 'app',\n",
       " 'sao',\n",
       " 'mu',\n",
       " 'ìï',\n",
       " 'predict',\n",
       " 'yetund',\n",
       " 'sent',\n",
       " 'bother',\n",
       " 'involv',\n",
       " 'impos',\n",
       " 'apologis',\n",
       " 'del',\n",
       " 'bak',\n",
       " 'sum',\n",
       " 'lucyxx',\n",
       " 'tmorrow',\n",
       " 'answer',\n",
       " 'sunshin',\n",
       " 'quiz',\n",
       " 'q',\n",
       " 'top',\n",
       " 'soni',\n",
       " 'dvd',\n",
       " 'player',\n",
       " 'countri',\n",
       " 'algarv',\n",
       " 'ansr',\n",
       " 'sp',\n",
       " 'tyron',\n",
       " 'laid',\n",
       " 'dog',\n",
       " 'direct',\n",
       " 'join',\n",
       " 'largest',\n",
       " 'bt',\n",
       " 'txting',\n",
       " 'gravel',\n",
       " 'nt',\n",
       " 'ecnuma',\n",
       " 'haf',\n",
       " 'msn',\n",
       " 'yiju',\n",
       " 'hotmail',\n",
       " 'befor',\n",
       " 'activ',\n",
       " 'chat',\n",
       " 'svc',\n",
       " 'hardcor',\n",
       " 'age',\n",
       " 'yr',\n",
       " 'lazi',\n",
       " 'type',\n",
       " 'lect',\n",
       " 'pouch',\n",
       " 'sir',\n",
       " 'mail',\n",
       " 'swt',\n",
       " 'nver',\n",
       " 'tire',\n",
       " 'littl',\n",
       " 'lovabl',\n",
       " 'person',\n",
       " 'coz',\n",
       " 'somtim',\n",
       " 'occupi',\n",
       " 'biggest',\n",
       " 'heart',\n",
       " 'gud',\n",
       " 'ninum',\n",
       " 'open',\n",
       " 'ya',\n",
       " 'dot',\n",
       " 'what',\n",
       " 'staff',\n",
       " 'randi',\n",
       " 'sexi',\n",
       " 'femal',\n",
       " 'local',\n",
       " 'luv',\n",
       " 'netcollex',\n",
       " 'ltd',\n",
       " 'ummma',\n",
       " 'begin',\n",
       " 'qatar',\n",
       " 'pray',\n",
       " 'hard',\n",
       " 'delet',\n",
       " 'sindu',\n",
       " 'birla',\n",
       " 'soft',\n",
       " 'wine',\n",
       " 'flow',\n",
       " 'thk',\n",
       " 'plaza',\n",
       " 'typic',\n",
       " 'everywher',\n",
       " 'dirt',\n",
       " 'floor',\n",
       " 'window',\n",
       " 'shirt',\n",
       " 'sometim',\n",
       " 'mouth',\n",
       " 'dream',\n",
       " 'without',\n",
       " 'chore',\n",
       " 'joy',\n",
       " 'tv',\n",
       " 'exist',\n",
       " 'hail',\n",
       " 'mist',\n",
       " 'becom',\n",
       " 'aaooooright',\n",
       " 'leav',\n",
       " 'hous',\n",
       " 'interview',\n",
       " 'boy',\n",
       " 'annonc',\n",
       " 'arrang',\n",
       " 'keep',\n",
       " 'safe',\n",
       " 'envi',\n",
       " 'everyon',\n",
       " 'parent',\n",
       " 'hand',\n",
       " 'excit',\n",
       " 'spend',\n",
       " 'bootydeli',\n",
       " 'f',\n",
       " 'bangbab',\n",
       " 'order',\n",
       " 'content',\n",
       " 'goto',\n",
       " 'bangb',\n",
       " 'internet',\n",
       " 'menu',\n",
       " 'cultur',\n",
       " 'modul',\n",
       " 'snum',\n",
       " 'avoid',\n",
       " 'missunderstd',\n",
       " 'wit',\n",
       " 'belov',\n",
       " 'escap',\n",
       " 'fanci',\n",
       " 'bridg',\n",
       " 'lager',\n",
       " 'complet',\n",
       " 'form',\n",
       " 'clark',\n",
       " 'also',\n",
       " 'utter',\n",
       " 'wast',\n",
       " 'axi',\n",
       " 'bank',\n",
       " 'hmmm',\n",
       " 'hop',\n",
       " 'muz',\n",
       " 'discuss',\n",
       " 'liao',\n",
       " 'bloodi',\n",
       " 'hell',\n",
       " 'cant',\n",
       " 'believ',\n",
       " 'surnam',\n",
       " 'mr',\n",
       " 'ill',\n",
       " 'clue',\n",
       " 'spanish',\n",
       " 'bath',\n",
       " 'carlo',\n",
       " 'mall',\n",
       " 'stay',\n",
       " 'til',\n",
       " 'smoke',\n",
       " 'worth',\n",
       " 'doesnt',\n",
       " 'log',\n",
       " 'spoke',\n",
       " 'maneesha',\n",
       " 'satisfi',\n",
       " 'experi',\n",
       " 'toll',\n",
       " 'lift',\n",
       " 'especi',\n",
       " 'approach',\n",
       " 'studi',\n",
       " 'grnum',\n",
       " 'trust',\n",
       " 'guy',\n",
       " 'bye',\n",
       " 'handsom',\n",
       " 'toward',\n",
       " 'mummi',\n",
       " 'boytoy',\n",
       " 'awesom',\n",
       " 'minut',\n",
       " 'freephon',\n",
       " 'xma',\n",
       " 'radio',\n",
       " 'ju',\n",
       " 'si',\n",
       " 'uniqu',\n",
       " 'august',\n",
       " 'areyouuniqu',\n",
       " 'leagu',\n",
       " 'touch',\n",
       " 'deal',\n",
       " 'cours',\n",
       " 'howev',\n",
       " 'suggest',\n",
       " 'abl',\n",
       " 'or',\n",
       " 'everi',\n",
       " 'stool',\n",
       " 'settl',\n",
       " 'wishin',\n",
       " 'mrng',\n",
       " 'hav',\n",
       " 'stori',\n",
       " 'hamster',\n",
       " 'dead',\n",
       " 'tmr',\n",
       " 'orchard',\n",
       " 'mrt',\n",
       " 'kate',\n",
       " 'babyjontet',\n",
       " 'found',\n",
       " 'enc',\n",
       " 'buck',\n",
       " 'darlin',\n",
       " 'ive',\n",
       " 'colleg',\n",
       " 'refil',\n",
       " 'success',\n",
       " 'inr',\n",
       " 'decim',\n",
       " 'keralacircl',\n",
       " 'prepaid',\n",
       " 'balanc',\n",
       " 'rs',\n",
       " 'transact',\n",
       " 'id',\n",
       " 'kr',\n",
       " 'goodmorn',\n",
       " 'sleep',\n",
       " 'ga',\n",
       " 'alter',\n",
       " 'dat',\n",
       " 'ericsson',\n",
       " 'oso',\n",
       " 'can',\n",
       " 'not',\n",
       " 'oredi',\n",
       " 'straight',\n",
       " 'dogg',\n",
       " 'connect',\n",
       " 'refund',\n",
       " 'bill',\n",
       " 'shoot',\n",
       " 'big',\n",
       " 'readi',\n",
       " 'bruv',\n",
       " 'break',\n",
       " 'semest',\n",
       " 'noe',\n",
       " 'leh',\n",
       " 'sound',\n",
       " 'head',\n",
       " 'slept',\n",
       " 'past',\n",
       " 'easi',\n",
       " 'sen',\n",
       " 'exam',\n",
       " 'march',\n",
       " 'atm',\n",
       " 'regist',\n",
       " 'os',\n",
       " 'ubandu',\n",
       " 'instal',\n",
       " 'disk',\n",
       " 'import',\n",
       " 'file',\n",
       " 'system',\n",
       " 'repair',\n",
       " 'shop',\n",
       " 'romant',\n",
       " 'nite',\n",
       " 'sceneri',\n",
       " 'tc',\n",
       " 'biz',\n",
       " 'numoptout',\n",
       " 'numgbp',\n",
       " 'mtmsgnum',\n",
       " 'appreci',\n",
       " 'partner',\n",
       " 'career',\n",
       " 'flyng',\n",
       " 'horo',\n",
       " 'star',\n",
       " 'sign',\n",
       " 'g',\n",
       " 'ari',\n",
       " 'compani',\n",
       " 'elama',\n",
       " 'po',\n",
       " 'mudyadhu',\n",
       " 'strict',\n",
       " 'teacher',\n",
       " 'bcoz',\n",
       " 'teach',\n",
       " 'conduct',\n",
       " 'gandhipuram',\n",
       " 'walk',\n",
       " 'cross',\n",
       " 'road',\n",
       " 'side',\n",
       " 'street',\n",
       " 'rubber',\n",
       " 'batteri',\n",
       " 'die',\n",
       " 'flirt',\n",
       " 'sam',\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features = list(all_words.keys())[:1500]\n",
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb73895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed[0]: go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n",
      "features at 0th index: [('go', True), ('jurong', True), ('point', True), ('crazi', True), ('avail', True), ('bugi', True), ('n', True), ('great', True), ('world', True), ('la', True)]\n",
      "go\n",
      "jurong\n",
      "point\n",
      "crazi\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "# find_features function will determine which of the 1500 word features are contained in the email/message\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "    return features\n",
    "# example\n",
    "print('processed[0]:',processed[0])\n",
    "features = find_features(processed[0])\n",
    "print('features at 0th index:',list(features.items())[:10])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5c5c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it for all the messages\n",
    "messages = list(zip(processed, Y))\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "175ffcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a32e559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4179\n",
      "Testing: 1393\n"
     ]
    }
   ],
   "source": [
    "print('Training:',len(training))\n",
    "print('Testing:',len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a777243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 98.34888729361091\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca13db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 94.18521177315147\n",
      "Decision Tree Accuracy: 97.20028715003589\n",
      "Random Forest Accuracy: 98.34888729361091\n",
      "Logistic Regression Accuracy: 98.56424982053123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adca5ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 98.56424982053123\n"
     ]
    }
   ],
   "source": [
    "# ensemble methods - Voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad861694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class label prediction for testing set\n",
    "txt_features, labels = zip(*testing)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0fa1952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1196\n",
      "           1       1.00      0.87      0.93       197\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.99      0.94      0.96      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1196    0\n",
       "       spam        25  172"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9f367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
